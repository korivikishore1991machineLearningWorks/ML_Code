{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13f3437",
   "metadata": {},
   "source": [
    "# Finding best model and hyper parameter tunning using GridSearchCV\n",
    "#### For iris flower dataset in sklearn library, we are going to find out best model and best hyper parameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd45146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris flower dataset\n",
    "from sklearn import svm, datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541b419",
   "metadata": {},
   "source": [
    "## Approach 1: Use train_test_split and manually tune parameters by trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb89d9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)\n",
    "model = svm.SVC(kernel='rbf',C=30,gamma='auto')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa12b36",
   "metadata": {},
   "source": [
    "## Approach 2: Use K Fold Cross validation and loop through Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c129dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf_1': 0.9800000000000001,\n",
       " 'rbf_10': 0.9800000000000001,\n",
       " 'rbf_20': 0.9666666666666668,\n",
       " 'linear_1': 0.9800000000000001,\n",
       " 'linear_10': 0.9733333333333334,\n",
       " 'linear_20': 0.9666666666666666}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually try suppling models with different parameters to cross_val_score function with 5 fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# print(cross_val_score(svm.SVC(kernel='linear',C=10,gamma='auto'),iris.data, iris.target, cv=5))\n",
    "# print(cross_val_score(svm.SVC(kernel='rbf',C=10,gamma='auto'),iris.data, iris.target, cv=5))\n",
    "# print(cross_val_score(svm.SVC(kernel='rbf',C=20,gamma='auto'),iris.data, iris.target, cv=5))\n",
    "\n",
    "kernels = ['rbf', 'linear']\n",
    "C = [1,10,20]\n",
    "avg_scores = {}\n",
    "for kval in kernels:\n",
    "    for cval in C:\n",
    "        cv_scores = cross_val_score(svm.SVC(kernel=kval,C=cval,gamma='auto'),iris.data, iris.target, cv=5)\n",
    "        avg_scores[kval + '_' + str(cval)] = np.average(cv_scores)\n",
    "\n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44051c98",
   "metadata": {},
   "source": [
    "## Approach 3: Use GridSearchCV\n",
    "#### GridSearchCV does exactly same thing as for loop above but in a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883aa058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf.cv_results_:  {'mean_fit_time': array([0.00119753, 0.00119681, 0.00059843, 0.00059805, 0.00079765,\n",
      "       0.00100598]), 'std_fit_time': array([3.98898477e-04, 7.46684518e-04, 4.88616597e-04, 4.88305129e-04,\n",
      "       3.98826628e-04, 1.53646670e-05]), 'mean_score_time': array([0.00099711, 0.00039907, 0.00039897, 0.0001996 , 0.00019956,\n",
      "       0.        ]), 'std_score_time': array([8.84401178e-07, 4.88753305e-04, 4.88636085e-04, 3.99208069e-04,\n",
      "       3.99112701e-04, 0.00000000e+00]), 'param_C': masked_array(data=[1, 1, 10, 10, 20, 20],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear'],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 1, 'kernel': 'rbf'}, {'C': 1, 'kernel': 'linear'}, {'C': 10, 'kernel': 'rbf'}, {'C': 10, 'kernel': 'linear'}, {'C': 20, 'kernel': 'rbf'}, {'C': 20, 'kernel': 'linear'}], 'split0_test_score': array([0.96666667, 0.96666667, 0.96666667, 1.        , 0.96666667,\n",
      "       1.        ]), 'split1_test_score': array([1., 1., 1., 1., 1., 1.]), 'split2_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.9       , 0.9       ,\n",
      "       0.9       ]), 'split3_test_score': array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 0.96666667,\n",
      "       0.93333333]), 'split4_test_score': array([1., 1., 1., 1., 1., 1.]), 'mean_test_score': array([0.98      , 0.98      , 0.98      , 0.97333333, 0.96666667,\n",
      "       0.96666667]), 'std_test_score': array([0.01632993, 0.01632993, 0.01632993, 0.03887301, 0.03651484,\n",
      "       0.0421637 ]), 'rank_test_score': array([1, 1, 1, 4, 5, 6])}\n",
      "df:     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.001198      0.000399         0.000997    8.844012e-07       1   \n",
      "1       0.001197      0.000747         0.000399    4.887533e-04       1   \n",
      "2       0.000598      0.000489         0.000399    4.886361e-04      10   \n",
      "3       0.000598      0.000488         0.000200    3.992081e-04      10   \n",
      "4       0.000798      0.000399         0.000200    3.991127e-04      20   \n",
      "\n",
      "  param_kernel                         params  split0_test_score  \\\n",
      "0          rbf      {'C': 1, 'kernel': 'rbf'}           0.966667   \n",
      "1       linear   {'C': 1, 'kernel': 'linear'}           0.966667   \n",
      "2          rbf     {'C': 10, 'kernel': 'rbf'}           0.966667   \n",
      "3       linear  {'C': 10, 'kernel': 'linear'}           1.000000   \n",
      "4          rbf     {'C': 20, 'kernel': 'rbf'}           0.966667   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0                1.0           0.966667           0.966667                1.0   \n",
      "1                1.0           0.966667           0.966667                1.0   \n",
      "2                1.0           0.966667           0.966667                1.0   \n",
      "3                1.0           0.900000           0.966667                1.0   \n",
      "4                1.0           0.900000           0.966667                1.0   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.980000        0.016330                1  \n",
      "1         0.980000        0.016330                1  \n",
      "2         0.980000        0.016330                1  \n",
      "3         0.973333        0.038873                4  \n",
      "4         0.966667        0.036515                5  \n",
      "Reduced df:    param_C param_kernel  mean_test_score\n",
      "0       1          rbf         0.980000\n",
      "1       1       linear         0.980000\n",
      "2      10          rbf         0.980000\n",
      "3      10       linear         0.973333\n",
      "4      20          rbf         0.966667\n",
      "5      20       linear         0.966667\n",
      "clf.best_params_ {'C': 1, 'kernel': 'rbf'}\n",
      "clf.best_score_ 0.9800000000000001\n",
      "methods in clf:  ['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_is_fitted', '_check_n_features', '_check_refit_for_multimetric', '_estimator_type', '_format_results', '_get_param_names', '_get_tags', '_more_tags', '_pairwise', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_run_search', '_validate_data', 'best_estimator_', 'best_index_', 'best_params_', 'best_score_', 'classes_', 'cv', 'cv_results_', 'decision_function', 'error_score', 'estimator', 'fit', 'get_params', 'inverse_transform', 'multimetric_', 'n_features_in_', 'n_jobs', 'n_splits_', 'param_grid', 'pre_dispatch', 'predict', 'predict_log_proba', 'predict_proba', 'refit', 'refit_time_', 'return_train_score', 'score', 'score_samples', 'scorer_', 'scoring', 'set_params', 'transform', 'verbose']\n"
     ]
    }
   ],
   "source": [
    "# Using GridSearchCV to for Crossvalidation and looping through multiple Hyper parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "clf = GridSearchCV(svm.SVC(gamma='auto'), {\n",
    "    'C': [1,10,20],\n",
    "    'kernel': ['rbf','linear']\n",
    "}, cv=5, return_train_score=False)\n",
    "clf.fit(iris.data, iris.target)\n",
    "print(\"clf.cv_results_: \",clf.cv_results_)\n",
    "# Visualizing clf.cv_results_\n",
    "df = pd.DataFrame(clf.cv_results_)\n",
    "print(\"df: \",df.head())\n",
    "print(\"Reduced df: \",df[['param_C','param_kernel','mean_test_score']])\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "print(\"clf.best_score_\", clf.best_score_)\n",
    "print(\"methods in clf: \",dir(clf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef282bea",
   "metadata": {},
   "source": [
    "## Approach 4: Use RandomizedSearchCV\n",
    "#### RandomizedSearchCV reduces number of iterations using random combination of parameters. This is useful when you have too many parameters to try and your training time is longer. It helps reduce the cost of computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f7127dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0      20          rbf         0.966667\n",
       "1       1          rbf         0.980000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "        'C': [1,10,20],\n",
    "        'kernel': ['rbf','linear']\n",
    "    }, \n",
    "    cv=5, \n",
    "    return_train_score=False, \n",
    "    n_iter=2\n",
    ")\n",
    "rs.fit(iris.data, iris.target)\n",
    "pd.DataFrame(rs.cv_results_)[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b71c6",
   "metadata": {},
   "source": [
    "# Working on Hypertuning multiple models using Python JSON\n",
    "#### using Python JSON to automate the model and parameter attribute in the RandomizedSearchCV and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38643d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                best_params\n",
       "0                  svm    0.980000  {'C': 1, 'kernel': 'rbf'}\n",
       "1        random_forest    0.960000        {'n_estimators': 5}\n",
       "2  logistic_regression    0.966667                   {'C': 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing best out of 3 models\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Python JSON declearization\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# for tracking the score\n",
    "scores = []\n",
    "\n",
    "# Automation of GridsearchCV\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a21713",
   "metadata": {},
   "source": [
    "##### Based on above, I can conclude that SVM with C=1 and kernel='rbf' is the best model for solving my problem of iris flower classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95ab46",
   "metadata": {},
   "source": [
    "## Excersice\n",
    "#### Finding best model and hyper parameters for sklearn digits dataset classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4eed818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d2ffec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'naive_bayes_gaussian': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'naive_bayes_multinomial': {\n",
    "        'model': MultinomialNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'criterion': ['gini','entropy'],\n",
    "            \n",
    "        }\n",
    "    }     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62558027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\koriv\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\users\\koriv\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\users\\koriv\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\users\\koriv\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\users\\koriv\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\users\\koriv\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.947697</td>\n",
       "      <td>{'kernel': 'linear', 'C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.896535</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.922114</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naive_bayes_gaussian</td>\n",
       "      <td>0.806928</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naive_bayes_multinomial</td>\n",
       "      <td>0.870350</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.804690</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  best_score                   best_params\n",
       "0                      svm    0.947697  {'kernel': 'linear', 'C': 1}\n",
       "1            random_forest    0.896535          {'n_estimators': 10}\n",
       "2      logistic_regression    0.922114                      {'C': 1}\n",
       "3     naive_bayes_gaussian    0.806928                            {}\n",
       "4  naive_bayes_multinomial    0.870350                            {}\n",
       "5            decision_tree    0.804690      {'criterion': 'entropy'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  RandomizedSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(digits.data, digits.target)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49b6f6",
   "metadata": {},
   "source": [
    "### the winner is SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b207c9",
   "metadata": {},
   "source": [
    "# Other Options when using GridSearch:  \n",
    "cv_curr.cv_results_  \n",
    "cv_curr.best_score_  \n",
    "cv_curr.best_estimator_  \n",
    "cv_curr.best_params_  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2a4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
