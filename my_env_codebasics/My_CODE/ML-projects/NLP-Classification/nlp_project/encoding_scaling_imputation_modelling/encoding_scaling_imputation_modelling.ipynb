{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8188714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# import PreProcessing functions\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"C:\\\\Users\\\\koriv\\\\Desktop\\\\MachineLearning_DataScience\\\\Hands_On_Machine_Learning\\\\my_env_codebasics\\\\My_CODE\\\\ML-projects\\\\NLP-Classification\\\\nlp_project\\\\preProcessing\"))\n",
    "from fake_News_Classifier_preProcessing import Transformations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Import required pipeline and transformation libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import processing and evaluation libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Text Vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer #for bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #TF-IDF library\n",
    "\n",
    "# Import Model libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "# for scoring\n",
    "from sklearn.metrics import fbeta_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64733f0",
   "metadata": {},
   "source": [
    "# Import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfc8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training features\n",
    "import pathlib\n",
    "path_to_read_model = '..\\\\probleam_study' #Path of current working Directory\n",
    "with open(path_to_read_model + '\\\\trainFeatures_list.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58f02e",
   "metadata": {},
   "source": [
    "# Save Column Names of feature Training DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1936917",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ColumnNames = X.columns\n",
    "import pathlib\n",
    "path_to_write_output=str(pathlib.Path.cwd()) #Path of current working Directory\n",
    "with open(path_to_write_output + '\\\\feature_ColumnNames.pkl', 'wb') as handle:\n",
    " pickle.dump(feature_ColumnNames, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6f930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ColumnNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d110f",
   "metadata": {},
   "source": [
    "# Data PreProcessing, Transformation and Outlier Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbdb2734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>feature shape before cleaning:  (5824, 4)\n",
      ">>target shape before cleaning:  (5824,)\n",
      ">>feature shape after cleaning:  (5641, 1)\n",
      ">>target shape after cleaning:  (5641,)\n",
      ">>feature shape after preProcessing:  (5641, 1)\n",
      ">>target shape after preProcessing:  (5641,)\n"
     ]
    }
   ],
   "source": [
    "# Define a function to apply the imported functions\n",
    "def preProcessing(featureDF, targetDF, function_list):\n",
    "    for function in function_list:\n",
    "        featureDF, targetDF = function(featureDF, targetDF)\n",
    "    return featureDF, targetDF\n",
    "\n",
    "X, y = preProcessing(X, y, [Transformations])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab74bba",
   "metadata": {},
   "source": [
    "# Check the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b6a212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53bb147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09620cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94a9162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5641, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4bdac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5641,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfee33",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "842b1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Dictonary to store the Vectorizers and their parameters\n",
    "#vectorizer_grid = [CountVectorizer(), TfidfVectorizer()]\n",
    "# Python Dictonary to store the models and their parameters\n",
    "#modell_grid ={\n",
    "#    LogisticRegression(tol=0.0001, random_state=1):{\n",
    "#        'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#        'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#        'model__max_iter': list(range(100,800,1500)),\n",
    "#        'model__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#        'textVec__ngram_range': [(1,1), (1, 2), (1,3)],\n",
    "#        'textVec__max_features': [None, 1500, 15000]\n",
    "#    },\n",
    "#    RandomForestClassifier(random_state=1):{\n",
    "#        'model__n_estimators':[10, 100, 500, 1000],\n",
    "#        'model__criterion':['gini', 'entropy'],\n",
    "#        'model__max_depth':[10, 50, 100, 1000, None],\n",
    "#        'model__max_features': ['sqrt', 'log2'],\n",
    "#        'textVec__ngram_range': [(1,1), (1, 2), (1,3)],\n",
    "#        'textVec__max_features': [None, 1500, 15000]\n",
    "#    },\n",
    "#    MultinomialNB():{\n",
    "#        'model__alpha': [0, 1, 2],\n",
    "#        'model__fit_prior': [True, False],\n",
    "#        'textVec__ngram_range': [(1,1), (1, 2), (1,3)],\n",
    "#        'textVec__max_features': [None, 1500, 15000]        \n",
    "#    },\n",
    "#    GaussianNB():{\n",
    "#        'model__var_smoothing': [1e-12, 1e-9, 1e-6, 1e-3],\n",
    "#        'textVec__ngram_range': [(1,1), (1, 2), (1,3)] ,\n",
    "#        'textVec__max_features': [None, 1500, 15000]       \n",
    "#    },\n",
    "#    BernoulliNB():{\n",
    "#        'model__alpha': [0, 1, 2],\n",
    "#        'model__fit_prior': [True, False],\n",
    "#        'textVec__ngram_range': [(1,1), (1, 2), (1,3)],\n",
    "#        'textVec__max_features': [None, 1500, 15000]        \n",
    "#    }\n",
    "#}\n",
    "vectorizer_grid = [CountVectorizer(), TfidfVectorizer()]\n",
    "modell_grid ={\n",
    "    BernoulliNB():{\n",
    "        'model__alpha': [0, 1, 2],\n",
    "        'model__fit_prior': [True, False],\n",
    "        'textVec__ngram_range': [(1,1), (1, 2), (1,3)],\n",
    "        'textVec__max_features': [None, 1500, 15000, 30000]        \n",
    "    },\n",
    "    MultinomialNB():{\n",
    "        'model__alpha': [0, 1, 2],\n",
    "        'model__fit_prior': [True, False],\n",
    "        'textVec__ngram_range': [(1,1), (1, 2), (1,3)],\n",
    "        'textVec__max_features': [None, 1500, 15000, 30000]        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261090c2",
   "metadata": {},
   "source": [
    "## Theory for scoring  \n",
    "\tFalse negatives acceptable=> minimize False positives=>(optimize for prescision or Specificity) ex: spam filter => beta<1 for F-Beta score.  \n",
    "\tFalse positives acceptable=> minimize False negatives=>(optimize for Recall or Sensitivity) ex: Fradualent transactions => beta>1 for F-Beta score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1020e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Model:  BernoulliNB()\n",
      "Current vectorizer:  CountVectorizer()\n",
      "parameters:  {'model__alpha': [0, 1, 2], 'model__fit_prior': [True, False], 'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'textVec__max_features': [None, 1500, 15000, 30000]}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('textVec', CountVectorizer()),\n",
       "                                       ('scaler', None),\n",
       "                                       ('model', BernoulliNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0, 1, 2],\n",
       "                         'model__fit_prior': [True, False],\n",
       "                         'textVec__max_features': [None, 1500, 15000, 30000],\n",
       "                         'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(fbeta_score, beta=0.75, average=weighted),\n",
       "             verbose=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "--------------------------------------------------\n",
      ">>Model:  MultinomialNB()\n",
      "Current vectorizer:  CountVectorizer()\n",
      "parameters:  {'model__alpha': [0, 1, 2], 'model__fit_prior': [True, False], 'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'textVec__max_features': [None, 1500, 15000, 30000]}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('textVec', CountVectorizer()),\n",
       "                                       ('scaler', None),\n",
       "                                       ('model', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0, 1, 2],\n",
       "                         'model__fit_prior': [True, False],\n",
       "                         'textVec__max_features': [None, 1500, 15000, 30000],\n",
       "                         'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(fbeta_score, beta=0.75, average=weighted),\n",
       "             verbose=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "--------------------------------------------------\n",
      ">>Model:  BernoulliNB()\n",
      "Current vectorizer:  TfidfVectorizer()\n",
      "parameters:  {'model__alpha': [0, 1, 2], 'model__fit_prior': [True, False], 'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'textVec__max_features': [None, 1500, 15000, 30000]}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('textVec', TfidfVectorizer()),\n",
       "                                       ('scaler', None),\n",
       "                                       ('model', BernoulliNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0, 1, 2],\n",
       "                         'model__fit_prior': [True, False],\n",
       "                         'textVec__max_features': [None, 1500, 15000, 30000],\n",
       "                         'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(fbeta_score, beta=0.75, average=weighted),\n",
       "             verbose=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "--------------------------------------------------\n",
      ">>Model:  MultinomialNB()\n",
      "Current vectorizer:  TfidfVectorizer()\n",
      "parameters:  {'model__alpha': [0, 1, 2], 'model__fit_prior': [True, False], 'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'textVec__max_features': [None, 1500, 15000, 30000]}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('textVec', TfidfVectorizer()),\n",
       "                                       ('scaler', None),\n",
       "                                       ('model', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0, 1, 2],\n",
       "                         'model__fit_prior': [True, False],\n",
       "                         'textVec__max_features': [None, 1500, 15000, 30000],\n",
       "                         'textVec__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(fbeta_score, beta=0.75, average=weighted),\n",
       "             verbose=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Empty DataFrame to store the results from the CrossValidation Matrix\n",
    "full_df = pd.DataFrame()\n",
    "best_algos = {}\n",
    "\n",
    "#Iterate and fit the above specified Model and parameter dictonary\n",
    "for curr_Vectorizer in vectorizer_grid:\n",
    "    for curr_model, model_params in modell_grid.items():\n",
    "            print(\">>Model: \",curr_model)\n",
    "            print(\"Current vectorizer: \",curr_Vectorizer)\n",
    "            print(\"parameters: \",model_params)\n",
    "            print('\\n')\n",
    "            \n",
    "            # Building the Scaler for distance and gradient descent based algorithms\n",
    "            algo_name = str(curr_model).split('(')[0]\n",
    "            textVec_name = str(curr_Vectorizer).split('(')[0]\n",
    "            curr_scaler = MinMaxScaler((0,1)) if algo_name == 'LogisticRegression' or algo_name == 'KNeighborsClassifier'  else None\n",
    "            \n",
    "            # Buiding Modelling Pipe line\n",
    "            modelling_pipe = Pipeline([\n",
    "                ('textVec', curr_Vectorizer),\n",
    "                ('scaler', curr_scaler),\n",
    "                ('model', curr_model)\n",
    "            ])\n",
    "            \n",
    "            ##GridSearch K folds cross validation definition with current model and its parameters\n",
    "            ### scoring='accuracy' for balanced datasets\n",
    "            ### scoring= 'balanced_accuracy' or 'f1' for unbalanced datasets\n",
    "            ### False negatives acceptable=>(optimize for prescision or Specificity) ex: spam filter\n",
    "            # cv_curr =  GridSearchCV(modelling_pipe, model_params, cv=5, return_train_score=True, scoring='balanced_accuracy', verbose=3, n_jobs=-1)\n",
    "            #cv_curr =  RandomizedSearchCV(modelling_pipe, model_params, cv=5, return_train_score=True, scoring='accuracy', verbose=3, n_jobs=-1, n_iter=100)\n",
    "            ## to tune for precision and Recall using custom scorer via F-Beta Score\n",
    "            ### use average='macro' for mutilable target classification in the scoring method\n",
    "            cv_curr =  GridSearchCV(modelling_pipe, model_params, cv=5, \n",
    "                                    return_train_score=True, \n",
    "                                    scoring=make_scorer(fbeta_score, beta=0.75, average='macro', greater_is_better=True), \n",
    "                                    verbose=3, n_jobs=-1)\n",
    "            ##fit the data to the defined grid search\n",
    "            display(cv_curr)\n",
    "            cv_curr.fit(X.title, y)\n",
    "                        \n",
    "            ##Create a DataFrame out of the CrossValidation results\n",
    "            all_res = pd.DataFrame(cv_curr.cv_results_)\n",
    "            \n",
    "            ##Create a temp Datframe with only values of 'params', 'mean_test_score' from CrossValidation results\n",
    "            temp = all_res.loc[:, ['params', 'mean_test_score']]\n",
    "            \n",
    "            ##Get the name of the Model in use from the specified Model and parameter dictonary\n",
    "            temp['algo'] = algo_name+'_'+textVec_name\n",
    "            \n",
    "            ##Merge the temporary dataframes and results to final DataFrame and Dictonary\n",
    "            full_df = pd.concat([full_df, temp])\n",
    "            best_algos[algo_name+'_'+textVec_name]={}\n",
    "            best_algos[algo_name+'_'+textVec_name]['best_estimator'] = cv_curr.best_estimator_\n",
    "            best_algos[algo_name+'_'+textVec_name]['best_mean_test_score'] = cv_curr.best_score_\n",
    "            print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40daff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BernoulliNB_CountVectorizer': {'best_estimator': Pipeline(steps=[('textVec', CountVectorizer(ngram_range=(1, 2))),\n",
       "                  ('scaler', None),\n",
       "                  ('model', BernoulliNB(alpha=2, fit_prior=False))]),\n",
       "  'best_mean_test_score': 0.9170658580863235},\n",
       " 'MultinomialNB_CountVectorizer': {'best_estimator': Pipeline(steps=[('textVec',\n",
       "                   CountVectorizer(max_features=15000, ngram_range=(1, 3))),\n",
       "                  ('scaler', None),\n",
       "                  ('model', MultinomialNB(alpha=1, fit_prior=False))]),\n",
       "  'best_mean_test_score': 0.8861378107583524},\n",
       " 'BernoulliNB_TfidfVectorizer': {'best_estimator': Pipeline(steps=[('textVec', TfidfVectorizer(ngram_range=(1, 2))),\n",
       "                  ('scaler', None),\n",
       "                  ('model', BernoulliNB(alpha=2, fit_prior=False))]),\n",
       "  'best_mean_test_score': 0.9170658580863235},\n",
       " 'MultinomialNB_TfidfVectorizer': {'best_estimator': Pipeline(steps=[('textVec',\n",
       "                   TfidfVectorizer(max_features=15000, ngram_range=(1, 3))),\n",
       "                  ('scaler', None),\n",
       "                  ('model', MultinomialNB(alpha=1, fit_prior=False))]),\n",
       "  'best_mean_test_score': 0.8663658328244648}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the best Regressor Models per each Algorithm and thier scores on the Training Data\n",
    "best_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7ca247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>{'model__alpha': 2, 'model__fit_prior': False, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.917066</td>\n",
       "      <td>BernoulliNB_CountVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>{'model__alpha': 2, 'model__fit_prior': False, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.917066</td>\n",
       "      <td>BernoulliNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'model__alpha': 2, 'model__fit_prior': True, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.916669</td>\n",
       "      <td>BernoulliNB_CountVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'model__alpha': 2, 'model__fit_prior': True, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.916669</td>\n",
       "      <td>BernoulliNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>{'model__alpha': 2, 'model__fit_prior': True, 'textVec__max_features': 30000, 'textVec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.916493</td>\n",
       "      <td>BernoulliNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'model__alpha': 0, 'model__fit_prior': False, 'textVec__max_features': None, 'textVec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.760835</td>\n",
       "      <td>MultinomialNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'model__alpha': 0, 'model__fit_prior': False, 'textVec__max_features': 15000, 'textVec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.760835</td>\n",
       "      <td>MultinomialNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'model__alpha': 0, 'model__fit_prior': True, 'textVec__max_features': 15000, 'textVec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.757782</td>\n",
       "      <td>MultinomialNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'model__alpha': 0, 'model__fit_prior': True, 'textVec__max_features': 30000, 'textVec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.757782</td>\n",
       "      <td>MultinomialNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'model__alpha': 0, 'model__fit_prior': True, 'textVec__max_features': None, 'textVec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.757782</td>\n",
       "      <td>MultinomialNB_TfidfVectorizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            params  \\\n",
       "61   {'model__alpha': 2, 'model__fit_prior': False, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}   \n",
       "61   {'model__alpha': 2, 'model__fit_prior': False, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}   \n",
       "49    {'model__alpha': 2, 'model__fit_prior': True, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}   \n",
       "49    {'model__alpha': 2, 'model__fit_prior': True, 'textVec__max_features': None, 'textVec__ngram_range': (1, 2)}   \n",
       "58   {'model__alpha': 2, 'model__fit_prior': True, 'textVec__max_features': 30000, 'textVec__ngram_range': (1, 2)}   \n",
       "..                                                                                                             ...   \n",
       "12   {'model__alpha': 0, 'model__fit_prior': False, 'textVec__max_features': None, 'textVec__ngram_range': (1, 1)}   \n",
       "18  {'model__alpha': 0, 'model__fit_prior': False, 'textVec__max_features': 15000, 'textVec__ngram_range': (1, 1)}   \n",
       "6    {'model__alpha': 0, 'model__fit_prior': True, 'textVec__max_features': 15000, 'textVec__ngram_range': (1, 1)}   \n",
       "9    {'model__alpha': 0, 'model__fit_prior': True, 'textVec__max_features': 30000, 'textVec__ngram_range': (1, 1)}   \n",
       "0     {'model__alpha': 0, 'model__fit_prior': True, 'textVec__max_features': None, 'textVec__ngram_range': (1, 1)}   \n",
       "\n",
       "    mean_test_score                           algo  \n",
       "61         0.917066    BernoulliNB_CountVectorizer  \n",
       "61         0.917066    BernoulliNB_TfidfVectorizer  \n",
       "49         0.916669    BernoulliNB_CountVectorizer  \n",
       "49         0.916669    BernoulliNB_TfidfVectorizer  \n",
       "58         0.916493    BernoulliNB_TfidfVectorizer  \n",
       "..              ...                            ...  \n",
       "12         0.760835  MultinomialNB_TfidfVectorizer  \n",
       "18         0.760835  MultinomialNB_TfidfVectorizer  \n",
       "6          0.757782  MultinomialNB_TfidfVectorizer  \n",
       "9          0.757782  MultinomialNB_TfidfVectorizer  \n",
       "0          0.757782  MultinomialNB_TfidfVectorizer  \n",
       "\n",
       "[288 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the best Regressor Model\n",
    "full_df.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b13be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> best estimator:  Pipeline(steps=[('textVec', TfidfVectorizer(ngram_range=(1, 2))),\n",
      "                ('scaler', None),\n",
      "                ('model', BernoulliNB(alpha=2, fit_prior=False))])\n",
      ">> best_score:  0.9170658580863235\n"
     ]
    }
   ],
   "source": [
    "# Check for the best parameters and its score\n",
    "print(\">> best estimator: \",best_algos['BernoulliNB_TfidfVectorizer']['best_estimator'])\n",
    "print(\">> best_score: \",best_algos['BernoulliNB_TfidfVectorizer']['best_mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3e743",
   "metadata": {},
   "source": [
    "# Saving the best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd02dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [best_algos]\n",
    "import pathlib\n",
    "path_to_write_output=str(pathlib.Path.cwd()) #Path of current working Directory\n",
    "with open(path_to_write_output + '\\\\estimators.pkl', 'wb') as handle:\n",
    "    pickle.dump(estimators, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32fa52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
