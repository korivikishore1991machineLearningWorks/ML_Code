{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dfb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deplyment libraries\n",
    "import pickle\n",
    "\n",
    "# Importing required framework libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import required pipeline and transformation libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import processing and evaluation libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Regressors for Data\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Regressors for Imputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b7e9b",
   "metadata": {},
   "source": [
    "# Import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172b1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training features\n",
    "import pathlib\n",
    "path_to_read_model = 'C:\\\\Users\\\\koriv\\\\Desktop\\\\MachineLearning_DataScience\\\\Hands_On_Machine_Learning\\\\my_env_codebasics\\\\My_CODE\\\\ML-projects\\\\advanced_House_Price_Prediction-Regression\\\\probleam_study' #Path of current working Directory\n",
    "with open(path_to_read_model + '\\\\trainFeatures_list.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "    \n",
    "#Import testing features\n",
    "import pathlib\n",
    "path_to_read_model = 'C:\\\\Users\\\\koriv\\\\Desktop\\\\MachineLearning_DataScience\\\\Hands_On_Machine_Learning\\\\my_env_codebasics\\\\My_CODE\\\\ML-projects\\\\advanced_House_Price_Prediction-Regression\\\\probleam_study' #Path of current working Directory\n",
    "with open(path_to_read_model + '\\\\testFeatures_list.pkl', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8146be",
   "metadata": {},
   "source": [
    "# Save Column Names of feature Training DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfac1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ColumnNames = X.columns\n",
    "import pathlib\n",
    "path_to_write_output=str(pathlib.Path.cwd()) #Path of current working Directory\n",
    "with open(path_to_write_output + '\\\\feature_ColumnNames.pkl', 'wb') as handle:\n",
    " pickle.dump(feature_ColumnNames, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99852b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['area_type', 'availability', 'location', 'size', 'society',\n",
       "       'total_sqft', 'bath', 'balcony'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ColumnNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa031f8b",
   "metadata": {},
   "source": [
    "# Data PreProcessing, Transformation and Outlier Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d083ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation function\n",
    "def Transformations(featureDF, targetDF):\n",
    "    # Load the PreProcessing Objects needed for Transformations\n",
    "    #Import training features\n",
    "    import pathlib\n",
    "    path_to_read_model = 'C:\\\\Users\\\\koriv\\\\Desktop\\\\MachineLearning_DataScience\\\\Hands_On_Machine_Learning\\\\my_env_codebasics\\\\My_CODE\\\\ML-projects\\\\advanced_House_Price_Prediction-Regression\\\\preProcessingObjects_list' #Path of current working Directory\n",
    "    with open(path_to_read_model + '\\\\preProcessingObjects_list.pkl', 'rb') as f:\n",
    "        preProcessingObjects_list = pickle.load(f)\n",
    "    location_stats_greater_than_10 = preProcessingObjects_list[0]\n",
    "    \n",
    "    \n",
    "    # Feature Selection via Business knoledge. Society is dependednt on location\n",
    "    featureDF.drop(['society'], axis=1, inplace=True)\n",
    "    \n",
    "    # Duplicate elimination\n",
    "    featureDF.drop_duplicates(inplace=True)\n",
    "    # Update y matrix based X\n",
    "    ## since we've removed some data from X, we need to pass on these updations to y as well, as y doesn't know some of its corresponding X's have been deleted.\n",
    "    targetDF = targetDF[featureDF.index]\n",
    "    \n",
    "    # convert cat-col of total_sqft to float with null values also\n",
    "    def convert_sqft_to_num(curr_tuple):\n",
    "        try:\n",
    "            tokens = curr_tuple.split('-')\n",
    "            if len(tokens) == 2:\n",
    "                return (float(tokens[0])+float(tokens[1]))/2\n",
    "            return float(curr_tuple)\n",
    "        except:\n",
    "            return np.NaN\n",
    "    \n",
    "    featureDF['total_sqft'] = featureDF.total_sqft.apply(convert_sqft_to_num)\n",
    "    \n",
    "    # convert cat-col of availability to make both Immediate Possession and Ready To Move same and take only month, include null also.\n",
    "    def convert_availability(curr_tuple):\n",
    "        try:\n",
    "            curr_tuple = curr_tuple.lower()\n",
    "            if curr_tuple == 'ready to move' or curr_tuple == 'immediate possession':\n",
    "                return 'available_currently'\n",
    "            tokens = curr_tuple.split('-')\n",
    "            if len(tokens) == 2:\n",
    "                return tokens[1].strip()\n",
    "        except:\n",
    "            return np.NaN\n",
    "        \n",
    "    featureDF['availability'] = featureDF.availability.apply(convert_availability)\n",
    "    \n",
    "    # convert cat-col of size to number by the frist value with null value also\n",
    "    def convert_size_to_num(curr_tuple):\n",
    "        try:\n",
    "            tokens = curr_tuple.split(' ')\n",
    "            return float(tokens[0])\n",
    "        except:\n",
    "            return np.NaN\n",
    "        \n",
    "    featureDF['size'] = featureDF['size'].apply(convert_size_to_num)\n",
    "    \n",
    "    # Convert location to reduce the unique values in the column\n",
    "    X['location'] = X['location'].apply(lambda x: x if (x in location_stats_greater_than_10) else 'other')\n",
    "    \n",
    "    # Update y matrix based X\n",
    "    ## since we've removed some data from X, we need to pass on these updations to y as well, as y doesn't know some of its corresponding X's have been deleted.\n",
    "    targetDF = targetDF[featureDF.index]\n",
    "    \n",
    "    return featureDF, targetDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a385c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Removal function\n",
    "def outlierRemoval(featureDF, targetDF):\n",
    "    import json\n",
    "    outlier_Dict_DirPath = 'C:\\\\Users\\\\koriv\\\\Desktop\\\\MachineLearning_DataScience\\\\Hands_On_Machine_Learning\\\\my_env_codebasics\\\\My_CODE\\\\ML-projects\\\\advanced_House_Price_Prediction-Regression\\\\preProcessingObjects_list'\n",
    "    with open(outlier_Dict_DirPath+'\\\\outlier_Dict.json') as json_file:\n",
    "        outlier_Dict = json.load(json_file)\n",
    "    \n",
    "    for column in outlier_Dict:\n",
    "        lower_limit =outlier_Dict[column]['lower_limit']\n",
    "        upper_limit =outlier_Dict[column]['upper_limit']\n",
    "        print(\"column: %s, lower_limit: %s, upper_limit: %s\"%(column, lower_limit, upper_limit))\n",
    "        featureDF = featureDF[((featureDF[column]>lower_limit)&(featureDF[column]<upper_limit))| (featureDF[column].isna())]\n",
    "    \n",
    "    # Update y matrix based X\n",
    "    ## since we've removed some data from X, we need to pass on these updations to y as well, as y doesn't know some of its corresponding X's have been deleted.\n",
    "    targetDF = targetDF[featureDF.index]\n",
    "    \n",
    "    return featureDF, targetDF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2f7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: size, lower_limit: 0.5, upper_limit: 4.5\n",
      "column: total_sqft, lower_limit: 215.0, upper_limit: 2575.0\n",
      "column: bath, lower_limit: 0.5, upper_limit: 4.5\n",
      "column: balcony, lower_limit: -0.5, upper_limit: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Define a function to apply the imported functions\n",
    "def preProcessing(featureDF, targetDF, function_list):\n",
    "    for function in function_list:\n",
    "        featureDF, targetDF = function(featureDF, targetDF)\n",
    "    return featureDF, targetDF\n",
    "\n",
    "X, y = preProcessing(X, y, [Transformations, outlierRemoval])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33290d1a",
   "metadata": {},
   "source": [
    "# Check the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b19420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical columns in the DataFrame\n",
    "num_cols=['size', 'total_sqft', 'bath', 'balcony']\n",
    "## cols_to_be_OE\n",
    "col_catO = ['area_type']\n",
    "## cols_to_be_OHE\n",
    "col_catN = ['availability', 'location']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c06db0",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3bce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoder\n",
    "## Ordinal Encoder values for area_type\n",
    "area_type_unique =['Plot  Area', 'Built-up  Area', 'Super built-up  Area', 'Carpet  Area'] #In ascending order\n",
    "## Pipeline for imputer and Ordinal Encoder\n",
    "pp_catO = Pipeline([\n",
    "    ('col_catO', SimpleImputer(strategy='constant', add_indicator=True, fill_value='Plot  Area')),\n",
    "    ('catO', OrdinalEncoder(categories=[area_type_unique]))\n",
    "])\n",
    "\n",
    "# CloumnTransfer for Encoding\n",
    "ct_O = ColumnTransformer([\n",
    "    ('pp_catO', pp_catO, col_catO),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd28b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_O.fit(X)\n",
    "X[X.columns] = ct_O.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ee668",
   "metadata": {},
   "source": [
    "# Pipelines for Nominal Encoding using OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "906988ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoder\n",
    "## pipeline for imputer and One Hot Encoder for Nominal Columns\n",
    "pp_catN = Pipeline([\n",
    "    ('col_catN', SimpleImputer(strategy='constant', add_indicator=False, fill_value='missing')),\n",
    "    ('catN', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a23e8",
   "metadata": {},
   "source": [
    "# Imputing and Scaling for Numerical columns[including Oridnal Clumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51069b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['size', 'total_sqft', 'bath', 'balcony', 'area_type']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = num_cols+col_catO\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba61d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline to processes Numerical and Catogorical columns\n",
    "pp_num = Pipeline([\n",
    "    ('scaler', MinMaxScaler((0,1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b954c",
   "metadata": {},
   "source": [
    "# Column Transformer for Nominal Encoding and Imputing & Scaling for Numerical Columns[including Ordinal Columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67cf9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_ohe_sca = ColumnTransformer([\n",
    "    ('pp_catN', pp_catN, col_catN),\n",
    "    ('pp_num', pp_num, num_cols)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd75ab",
   "metadata": {},
   "source": [
    "# Model Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e0d8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'imputer__estimator':[BayesianRidge(),ExtraTreesRegressor(n_estimators=10, random_state=0),KNeighborsRegressor(n_neighbors=15)]\n",
    "# Python Dictonary to store the models and their parameters\n",
    "grid ={\n",
    "    RandomForestRegressor(random_state = 0):{\n",
    "        'model__n_estimators':[100,300],\n",
    "        'model__max_depth':[5, 9, 13],\n",
    "        'model__min_samples_split':[2,4,8],\n",
    "        'imputer__estimator':[BayesianRidge()]\n",
    "        },\n",
    "    Lasso(tol=0.0001, random_state = 0):{\n",
    "        'model__alpha':[0.1, 1, 10],\n",
    "        'model__max_iter':[100, 1000],\n",
    "        'imputer__estimator':[BayesianRidge()]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcebddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Model:  RandomForestRegressor(random_state=0)\n",
      "parameters:  {'model__n_estimators': [100, 300], 'model__max_depth': [5, 9, 13], 'model__min_samples_split': [2, 4, 8], 'imputer__estimator': [BayesianRidge()]}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "--------------------------------------------------\n",
      ">>Model:  Lasso(random_state=0)\n",
      "parameters:  {'model__alpha': [0.1, 1, 10], 'model__max_iter': [100, 1000], 'imputer__estimator': [BayesianRidge()]}\n",
      "\n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Empty DataFrame to store the results from the CrossValidation Matrix\n",
    "full_df = pd.DataFrame()\n",
    "best_algos = {}\n",
    "\n",
    "#Iterate and fit the above specified Model and parameter dictonary\n",
    "for curr_model, model_params in grid.items():\n",
    "    print(\">>Model: \",curr_model)\n",
    "    print(\"parameters: \",model_params)\n",
    "    print('\\n')\n",
    "    \n",
    "    # pipelne with the Data Transformations and model\n",
    "    pipe = Pipeline([\n",
    "        ('ct_ohe_sca', ct_ohe_sca),\n",
    "        ('imputer', IterativeImputer()),\n",
    "        ('model', curr_model)\n",
    "    ])\n",
    "    \n",
    "    ##GridSearch K folds cross validation definition with current model and its parameters\n",
    "    cv_curr =  GridSearchCV(pipe, model_params, cv=5, return_train_score=False, scoring='neg_root_mean_squared_error', verbose=3, n_jobs=-1) # optionally can use ‘explained_variance’ in the scoring for scoring based on adjusted R2.\n",
    "    #cv_curr =  RandomizedSearchCV(curr_model, model_params, cv=5, n_iter=100, return_train_score=False, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "    ##fit the data to the defined grid search\n",
    "    cv_curr.fit(X, y)\n",
    "    \n",
    "    ##Create a DataFrame out of the CrossValidation results\n",
    "    all_res = pd.DataFrame(cv_curr.cv_results_)\n",
    "    \n",
    "    ##Create a temp Datframe with only values of 'params', 'mean_test_score' from CrossValidation results\n",
    "    temp = all_res.loc[:, ['params', 'mean_test_score']]\n",
    "    \n",
    "    ##Get the name of the Model in use from the specified Model and parameter dictonary\n",
    "    algo_name = str(curr_model).split('(')[0]\n",
    "    temp['algo'] = algo_name\n",
    "    \n",
    "    ##Merge the temporary dataframes and results to final DataFrame and Dictonary\n",
    "    full_df = pd.concat([full_df, temp])\n",
    "    best_algos[algo_name]={}\n",
    "    best_algos[algo_name]['best_estimator'] = cv_curr.best_estimator_\n",
    "    best_algos[algo_name]['best_mean_test_score'] = cv_curr.best_score_\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fc2905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelne with the Data Transformations and model\n",
    "#pipe = Pipeline([\n",
    "#    ('ct_ohe_sca', ct_ohe_sca),\n",
    "#    ('imputer', IterativeImputer()),\n",
    "#    ('model', RandomForestRegressor(random_state = 0))\n",
    "#])\n",
    "#\n",
    "## parameters of the model\n",
    "#params = {\n",
    "#    'model__n_estimators':[18, 36, 216],\n",
    "#    'model__max_depth':[5, 9, 13],\n",
    "#    'model__min_samples_split':[2,4,6,8],\n",
    "#    'imputer__estimator':[KNeighborsRegressor(n_neighbors=15)]\n",
    "#}\n",
    "#\n",
    "## CrossValidation\n",
    "#gs = GridSearchCV(pipe, param_grid=params, cv=5, return_train_score=False, scoring='neg_root_mean_squared_error', verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89bfd8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct_ohe_sca',\n",
       "                                        ColumnTransformer(transformers=[('pp_catN',\n",
       "                                                                         Pipeline(steps=[('col_catN',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('catN',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         ['availability',\n",
       "                                                                          'location']),\n",
       "                                                                        ('pp_num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          MinMaxScaler())]),\n",
       "                                                                         ['size',\n",
       "                                                                          'total_sqft',\n",
       "                                                                          'bath',\n",
       "                                                                          'balcony',\n",
       "                                                                          'area_type'])])),\n",
       "                                       ('imputer', IterativeImputer()),\n",
       "                                       ('model',\n",
       "                                        RandomForestRegressor(random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'imputer__estimator': [KNeighborsRegressor(n_neighbors=15)],\n",
       "                         'model__max_depth': [5, 9, 13],\n",
       "                         'model__min_samples_split': [2, 4, 6, 8],\n",
       "                         'model__n_estimators': [50, 100]},\n",
       "             scoring='neg_root_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data\n",
    "#gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40dce400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.468456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.493658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.652725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.674995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.678507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.704918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.716374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.720507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.750041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.797122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.801737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.811216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.827154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.856321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.922549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.930118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.987097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-44.989633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-45.047325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-45.052808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-45.289492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-45.312243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'imputer__estimator': KNeighborsRegressor(n_n...</td>\n",
       "      <td>-45.523653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score\n",
       "15  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.468456\n",
       "23  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.493658\n",
       "14  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.652725\n",
       "1   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.674995\n",
       "3   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.678507\n",
       "22  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.704918\n",
       "7   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.716374\n",
       "5   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.720507\n",
       "13  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.750041\n",
       "0   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.762326\n",
       "2   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.797122\n",
       "6   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.801737\n",
       "21  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.811216\n",
       "11  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.827154\n",
       "4   {'imputer__estimator': KNeighborsRegressor(n_n...       -44.856321\n",
       "12  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.922549\n",
       "10  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.930118\n",
       "19  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.987097\n",
       "20  {'imputer__estimator': KNeighborsRegressor(n_n...       -44.989633\n",
       "18  {'imputer__estimator': KNeighborsRegressor(n_n...       -45.047325\n",
       "9   {'imputer__estimator': KNeighborsRegressor(n_n...       -45.052808\n",
       "8   {'imputer__estimator': KNeighborsRegressor(n_n...       -45.289492\n",
       "17  {'imputer__estimator': KNeighborsRegressor(n_n...       -45.312243\n",
       "16  {'imputer__estimator': KNeighborsRegressor(n_n...       -45.523653"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.pandas.set_option('display.max_columns', None)\n",
    "#pd.DataFrame(gs.cv_results_).loc[:, ['params', 'mean_test_score']].sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1214ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>algo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.480102</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.554485</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.578146</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.584909</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.738451</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.752784</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.780420</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.895597</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.899281</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.904252</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.906251</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-44.907781</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-45.034573</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-45.035627</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-45.036949</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-45.177950</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-45.267556</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-45.407047</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-48.094746</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-48.094746</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-50.034834</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-50.034834</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-65.702213</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'imputer__estimator': BayesianRidge(), 'model...</td>\n",
       "      <td>-65.702213</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "17  {'imputer__estimator': BayesianRidge(), 'model...       -44.480102   \n",
       "11  {'imputer__estimator': BayesianRidge(), 'model...       -44.554485   \n",
       "16  {'imputer__estimator': BayesianRidge(), 'model...       -44.578146   \n",
       "10  {'imputer__estimator': BayesianRidge(), 'model...       -44.584909   \n",
       "2   {'imputer__estimator': BayesianRidge(), 'model...       -44.738451   \n",
       "0   {'imputer__estimator': BayesianRidge(), 'model...       -44.752784   \n",
       "4   {'imputer__estimator': BayesianRidge(), 'model...       -44.780420   \n",
       "9   {'imputer__estimator': BayesianRidge(), 'model...       -44.895597   \n",
       "5   {'imputer__estimator': BayesianRidge(), 'model...       -44.899281   \n",
       "3   {'imputer__estimator': BayesianRidge(), 'model...       -44.904252   \n",
       "1   {'imputer__estimator': BayesianRidge(), 'model...       -44.906251   \n",
       "8   {'imputer__estimator': BayesianRidge(), 'model...       -44.907781   \n",
       "15  {'imputer__estimator': BayesianRidge(), 'model...       -45.034573   \n",
       "7   {'imputer__estimator': BayesianRidge(), 'model...       -45.035627   \n",
       "6   {'imputer__estimator': BayesianRidge(), 'model...       -45.036949   \n",
       "14  {'imputer__estimator': BayesianRidge(), 'model...       -45.177950   \n",
       "13  {'imputer__estimator': BayesianRidge(), 'model...       -45.267556   \n",
       "12  {'imputer__estimator': BayesianRidge(), 'model...       -45.407047   \n",
       "0   {'imputer__estimator': BayesianRidge(), 'model...       -48.094746   \n",
       "1   {'imputer__estimator': BayesianRidge(), 'model...       -48.094746   \n",
       "2   {'imputer__estimator': BayesianRidge(), 'model...       -50.034834   \n",
       "3   {'imputer__estimator': BayesianRidge(), 'model...       -50.034834   \n",
       "4   {'imputer__estimator': BayesianRidge(), 'model...       -65.702213   \n",
       "5   {'imputer__estimator': BayesianRidge(), 'model...       -65.702213   \n",
       "\n",
       "                     algo  \n",
       "17  RandomForestRegressor  \n",
       "11  RandomForestRegressor  \n",
       "16  RandomForestRegressor  \n",
       "10  RandomForestRegressor  \n",
       "2   RandomForestRegressor  \n",
       "0   RandomForestRegressor  \n",
       "4   RandomForestRegressor  \n",
       "9   RandomForestRegressor  \n",
       "5   RandomForestRegressor  \n",
       "3   RandomForestRegressor  \n",
       "1   RandomForestRegressor  \n",
       "8   RandomForestRegressor  \n",
       "15  RandomForestRegressor  \n",
       "7   RandomForestRegressor  \n",
       "6   RandomForestRegressor  \n",
       "14  RandomForestRegressor  \n",
       "13  RandomForestRegressor  \n",
       "12  RandomForestRegressor  \n",
       "0                   Lasso  \n",
       "1                   Lasso  \n",
       "2                   Lasso  \n",
       "3                   Lasso  \n",
       "4                   Lasso  \n",
       "5                   Lasso  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the best Regressor Model\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "full_df.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "998f50ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestRegressor': {'best_estimator': Pipeline(steps=[('ct_ohe_sca',\n",
       "                   ColumnTransformer(transformers=[('pp_catN',\n",
       "                                                    Pipeline(steps=[('col_catN',\n",
       "                                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                                   strategy='constant')),\n",
       "                                                                    ('catN',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                   sparse=False))]),\n",
       "                                                    ['availability', 'location']),\n",
       "                                                   ('pp_num',\n",
       "                                                    Pipeline(steps=[('scaler',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    ['size', 'total_sqft', 'bath',\n",
       "                                                     'balcony', 'area_type'])])),\n",
       "                  ('imputer', IterativeImputer(estimator=BayesianRidge())),\n",
       "                  ('model',\n",
       "                   RandomForestRegressor(max_depth=13, min_samples_split=8,\n",
       "                                         n_estimators=300, random_state=0))]),\n",
       "  'best_mean_test_score': -44.48010156813912},\n",
       " 'Lasso': {'best_estimator': Pipeline(steps=[('ct_ohe_sca',\n",
       "                   ColumnTransformer(transformers=[('pp_catN',\n",
       "                                                    Pipeline(steps=[('col_catN',\n",
       "                                                                     SimpleImputer(fill_value='missing',\n",
       "                                                                                   strategy='constant')),\n",
       "                                                                    ('catN',\n",
       "                                                                     OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                   sparse=False))]),\n",
       "                                                    ['availability', 'location']),\n",
       "                                                   ('pp_num',\n",
       "                                                    Pipeline(steps=[('scaler',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    ['size', 'total_sqft', 'bath',\n",
       "                                                     'balcony', 'area_type'])])),\n",
       "                  ('imputer', IterativeImputer(estimator=BayesianRidge())),\n",
       "                  ('model', Lasso(alpha=0.1, max_iter=100, random_state=0))]),\n",
       "  'best_mean_test_score': -48.0947463453915}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the best Regressor Models per each Algorithm and thier scores on the Training Data\n",
    "best_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f9d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> best estimator:  Pipeline(steps=[('ct_ohe_sca',\n",
      "                 ColumnTransformer(transformers=[('pp_catN',\n",
      "                                                  Pipeline(steps=[('col_catN',\n",
      "                                                                   SimpleImputer(fill_value='missing',\n",
      "                                                                                 strategy='constant')),\n",
      "                                                                  ('catN',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse=False))]),\n",
      "                                                  ['availability', 'location']),\n",
      "                                                 ('pp_num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   MinMaxScaler())]),\n",
      "                                                  ['size', 'total_sqft', 'bath',\n",
      "                                                   'balcony', 'area_type'])])),\n",
      "                ('imputer', IterativeImputer(estimator=BayesianRidge())),\n",
      "                ('model',\n",
      "                 RandomForestRegressor(max_depth=13, min_samples_split=8,\n",
      "                                       n_estimators=300, random_state=0))])\n",
      ">> best_score:  -44.48010156813912\n"
     ]
    }
   ],
   "source": [
    "# Check for the best parameters and its score\n",
    "print(\">> best estimator: \",best_algos['RandomForestRegressor']['best_estimator'])\n",
    "print(\">> best_score: \",best_algos['RandomForestRegressor']['best_mean_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61983f41",
   "metadata": {},
   "source": [
    "# Saving the Ordinal Column Transformer and best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4052a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [ct_O, best_algos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b809457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "path_to_write_output=str(pathlib.Path.cwd()) #Path of current working Directory\n",
    "with open(path_to_write_output + '\\\\estimators.pkl', 'wb') as handle:\n",
    "    pickle.dump(estimators, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150532d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
